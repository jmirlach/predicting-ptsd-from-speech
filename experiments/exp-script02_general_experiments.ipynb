{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, List\n",
    "import audeer\n",
    "import audmetric\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_interview = [\n",
    "    \"interview_question_facebook-wav2vec2\",\n",
    "    \"interview_question_opensmile\",\n",
    "    \"interview_windowed_facebook-wav2vec2\",\n",
    "    \"interview_windowed_opensmile\",\n",
    "]\n",
    "\n",
    "datasets_text = [\n",
    "    \"text_phrase_facebook-wav2vec2\",\n",
    "    \"text_phrase_opensmile\",\n",
    "    \"text_word_facebook-wav2vec2\",\n",
    "    \"text_word_opensmile\",\n",
    "]\n",
    "\n",
    "datasets_combined = [\n",
    "    \"combined_question-phrase_facebook-wav2vec2\",\n",
    "    \"combined_question-phrase_opensmile\",\n",
    "    \"combined_windowed-word_facebook-wav2vec2\",\n",
    "    \"combined_windowed-word_opensmile\",\n",
    "]\n",
    "\n",
    "features_folder = \"../data/final_datasets\"\n",
    "\n",
    "# Defining evaluation metrics\n",
    "metrics = {\n",
    "    'accuracy': accuracy_score,\n",
    "    'UAR': audmetric.unweighted_average_recall,\n",
    "    'roc_auc': roc_auc_score\n",
    "}\n",
    "\n",
    "seeds = [104, 105, 106]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(df_train: pd.DataFrame, X_test: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Train SVM with inner CV and return predictions.\"\"\"\n",
    "    df_train = df_train.set_index(\"patient\")\n",
    "    y = df_train[\"label\"]\n",
    "    X = df_train.drop(\"label\", axis=1)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    grid = {\n",
    "        \"kernel\": [\"rbf\", \"linear\"],\n",
    "        \"C\": [1e-4, 1e-3, 1e-1, 1, 5, 10],\n",
    "        \"gamma\": [\"auto\", \"scale\"],\n",
    "    }\n",
    "    search = GridSearchCV(\n",
    "        SVC(class_weight=\"balanced\"), grid, cv=KFold(3, shuffle=True, random_state=1)\n",
    "    )\n",
    "    search.fit(X_train, y)\n",
    "    best = search.best_estimator_\n",
    "\n",
    "    print(\"Train acc:\", accuracy_score(best.predict(X_train), y))\n",
    "    return best.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "def XGBoost(df_train: pd.DataFrame, X_test: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Train XGBoost with inner CV and return predictions.\"\"\"\n",
    "    df_train = df_train.set_index(\"patient\")\n",
    "    y = df_train[\"label\"]\n",
    "    X = df_train.drop(\"label\", axis=1)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    grid = {\"colsample_bytree\": [0.2, 0.6], \"max_depth\": [2, 4], \"n_estimators\": [10, 30]}\n",
    "    model = XGBClassifier(\n",
    "        random_state=42,\n",
    "        objective=\"reg:logistic\",\n",
    "        colsample_bytree=0.4,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=2,\n",
    "        alpha=10,\n",
    "        reg_lambda=10,\n",
    "        n_estimators=10,\n",
    "    )\n",
    "    search = GridSearchCV(model, grid, cv=KFold(3, shuffle=True, random_state=1))\n",
    "    search.fit(X_train, y)\n",
    "    best = search.best_estimator_\n",
    "\n",
    "    print(\"Train acc:\", accuracy_score(best.predict(X_train), y))\n",
    "    return best.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "def LR(df_train: pd.DataFrame, X_test: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Train Logistic Regression CV and return predictions.\"\"\"\n",
    "    df_train = df_train.set_index(\"patient\")\n",
    "    y = df_train[\"label\"]\n",
    "    X = df_train.drop(\"label\", axis=1)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    model = LogisticRegressionCV(\n",
    "        Cs=10, cv=3, penalty=\"l2\", max_iter=100, solver=\"liblinear\", random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y)\n",
    "\n",
    "    print(\"Train acc:\", model.score(X_train, y))\n",
    "    return model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "def DecisionTree(df_train: pd.DataFrame, X_test: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Train Decision Tree with inner CV and return predictions.\"\"\"\n",
    "    df_train = df_train.set_index(\"patient\")\n",
    "    y = df_train[\"label\"]\n",
    "    X = df_train.drop(\"label\", axis=1)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    grid = {\n",
    "        \"max_depth\": [2, 4, 6],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "    }\n",
    "    search = GridSearchCV(\n",
    "        DecisionTreeClassifier(random_state=42),\n",
    "        grid,\n",
    "        cv=KFold(3, shuffle=True, random_state=1),\n",
    "    )\n",
    "    search.fit(X_train, y)\n",
    "    best = search.best_estimator_\n",
    "\n",
    "    print(\"Train acc:\", best.score(X_train, y))\n",
    "    return best.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "def RandomForest(df_train: pd.DataFrame, X_test: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Train Random Forest with Leave-One-Group-Out CV and return predictions.\"\"\"\n",
    "    from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "    df_train = df_train.set_index(\"patient\")\n",
    "    y = df_train[\"label\"]\n",
    "    X = df_train.drop(\"label\", axis=1)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    grid = {\"n_estimators\": [10, 50, 100], \"max_depth\": [5, 10], \"min_samples_split\": [2, 5]}\n",
    "    logo = LeaveOneGroupOut()\n",
    "    search = GridSearchCV(\n",
    "        RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "        grid,\n",
    "        cv=logo,\n",
    "        refit=True,\n",
    "    )\n",
    "    search.fit(X_train, y, groups=df_train.index)\n",
    "    best = search.best_estimator_\n",
    "\n",
    "    print(\"Train acc:\", accuracy_score(best.predict(X_train), y))\n",
    "    return best.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in seeds:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    for feature_set in datasets_combined:\n",
    "        print(f\"Runs for {feature_set} at {datetime.now()}\")\n",
    "        for data in ['all','vor','nach']:\n",
    "            \n",
    "            if data!=\"all\":\n",
    "                results_path = os.path.join(f\"../data/results/{seed}_SVM/{feature_set}_results_only_{data}\")\n",
    "            else:\n",
    "                results_path = os.path.join(f\"../data/results/{seed}_SVM/{feature_set}_results\")\n",
    "\n",
    "            results = {\n",
    "                key: []\n",
    "                for key in metrics\n",
    "            }\n",
    "            \n",
    "            features = pd.read_csv(os.path.join(features_folder, f\"{feature_set}.csv\"), index_col=False)\n",
    "            \n",
    "            if data!='all':\n",
    "                features = features[features['timepoint'] == data]\n",
    "                \n",
    "            features = features.drop(['timepoint'],axis=1)\n",
    "            features = features.dropna()\n",
    "            \n",
    "            all_subjects = features['patient'].unique()\n",
    "            all_results = []\n",
    "            \n",
    "            for subj in audeer.progress_bar(all_subjects, total=len(all_subjects), desc='LOSO'):\n",
    "                df_test = features[features['patient']==subj]\n",
    "                df_test.set_index('patient', inplace=True)\n",
    "                y_test = df_test['label']\n",
    "                X_test = df_test.drop('label',axis=1)\n",
    "                df_train = features[features['patient']!=subj]\n",
    "                df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "                \n",
    "\n",
    "                experiment_folder = audeer.mkdir(\n",
    "                    os.path.join(results_path, f'{subj}'))\n",
    "                \n",
    "                df_test.insert(2, 'prediction', SVM(df_train, X_test))\n",
    "                df_test = df_test[['label','prediction']]\n",
    "                all_results.append(df_test)\n",
    "                \n",
    "                df_test.reset_index().to_csv(os.path.join(\n",
    "                    experiment_folder, 'results.csv'), index=False)\n",
    "               \n",
    "            results_df = pd.concat(all_results)\n",
    "            print(results_df)\n",
    "            \n",
    "            results = {\n",
    "                key: metrics[key](results_df['label'], results_df['prediction'])\n",
    "                for key in metrics\n",
    "            }\n",
    "            print(\"\\nResults per unit:\")\n",
    "            print(results)\n",
    "            with open(os.path.join(results_path, 'results.yaml'), 'w') as fp:\n",
    "                yaml.dump(results, fp)\n",
    "                \n",
    "            # Calculating results per subject:\n",
    "            results_df.reset_index(drop=False, inplace=True)\n",
    "            subj_list = []\n",
    "            label_list = []\n",
    "            prediction_list = []\n",
    "            for subj in all_subjects:\n",
    "                subj_list.append(subj)\n",
    "                subj_df = results_df[results_df['patient']==subj]\n",
    "                label_list.append(subj_df['label'].values[0])\n",
    "                prediction_list.append(subj_df['prediction'].value_counts().idxmax())\n",
    "            session_df = pd.DataFrame({'subject': subj_list, 'label': label_list, 'prediction': prediction_list})\n",
    "            session_df.reset_index().to_csv(os.path.join(results_path, 'results_session.csv'), index=False)\n",
    "            results = {\n",
    "                key: metrics[key](session_df['label'], session_df['prediction'])\n",
    "                for key in metrics\n",
    "            }\n",
    "            print(\"\\nResults per session:\")\n",
    "            print(results)\n",
    "            with open(os.path.join(results_path, 'results_session.yaml'), 'w') as fp:\n",
    "                yaml.dump(results, fp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

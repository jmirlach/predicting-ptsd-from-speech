{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "from typing import Tuple\n",
    "import audeer\n",
    "import audmetric\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_opensmile = [\n",
    "    \"interview_question_opensmile\",\n",
    "    \"interview_windowed_opensmile\",\n",
    "    \"text_phrase_opensmile\",\n",
    "    \"text_word_opensmile\",\n",
    "]\n",
    "datasets_combined = [\n",
    "    \"combined_question-phrase_opensmile\",\n",
    "    \"combined_windowed-word_opensmile\",\n",
    "]\n",
    "\n",
    "features_folder = \"../data/final_datasets\"\n",
    "\n",
    "# Defining evaluation metrics\n",
    "metrics = {\n",
    "    'accuracy': accuracy_score,\n",
    "    'UAR': audmetric.unweighted_average_recall,\n",
    "    'roc_auc': roc_auc_score\n",
    "}\n",
    "\n",
    "seeds = [104, 105, 106]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(df_train: pd.DataFrame, X_test: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"Train SVM with inner CV and return test predictions.\"\"\"\n",
    "    df_train = df_train.sample(frac=1).reset_index(drop=True).set_index(\"patient\")\n",
    "    y = df_train[\"label\"]\n",
    "    X = df_train.drop(\"label\", axis=1)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    grid = {\n",
    "        \"kernel\": [\"rbf\", \"linear\"],\n",
    "        \"C\": [1e-4, 1e-3, 1e-1, 1, 5, 10],\n",
    "        \"gamma\": [\"auto\", \"scale\"],\n",
    "    }\n",
    "    search = GridSearchCV(\n",
    "        SVC(class_weight=\"balanced\"), grid, cv=KFold(3, shuffle=True, random_state=1)\n",
    "    )\n",
    "    search.fit(X_train, y)\n",
    "    best = search.best_estimator_\n",
    "\n",
    "    print(\"Train acc:\", accuracy_score(best.predict(X_train), y))\n",
    "    return best.predict(X_test_scaled)\n",
    "\n",
    "def k_means(\n",
    "    df_clustering: pd.DataFrame,\n",
    "    subj: pd.DataFrame,\n",
    "    n_clusters: int = 2\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Cluster training subjects and assign cluster to held-out subj.\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    train_scaled = scaler.fit_transform(df_clustering)\n",
    "    model = KMeans(n_clusters=n_clusters, random_state=0, n_init=\"auto\")\n",
    "    model.fit(train_scaled)\n",
    "\n",
    "    subj_scaled = scaler.transform(subj)\n",
    "    subj_cluster = model.predict(subj_scaled)\n",
    "    return model.labels_, subj_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in seeds:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    for feature_set in datasets_opensmile:\n",
    "        print(f\"{feature_set} @ {datetime.now()}\")\n",
    "\n",
    "        results_path = os.path.join(f\"../data/results/{seed}_personalisation\", f\"{feature_set}_results\")\n",
    "        os.makedirs(results_path, exist_ok=True)\n",
    "\n",
    "        # load & clean\n",
    "        df = pd.read_csv(os.path.join(features_folder, f\"{feature_set}.csv\")).dropna()\n",
    "        df = df.drop(\"timepoint\", axis=1)\n",
    "        subjects = df[\"patient\"].unique()\n",
    "\n",
    "        all_results = []\n",
    "        for subj in audeer.progress_bar(subjects, desc=\"LOSO\"):\n",
    "            df_test = df[df[\"patient\"] == subj].set_index(\"patient\")\n",
    "            X_test = df_test.drop(\"label\", axis=1)\n",
    "\n",
    "            df_train = df[df[\"patient\"] != subj]\n",
    "            train_ids = df_train[\"patient\"].unique()\n",
    "\n",
    "            # cluster at subject-level\n",
    "            agg_train = df_train.groupby(\"patient\").mean().drop(\"label\", axis=1)\n",
    "            agg_subj = df_test.groupby(\"patient\").mean().drop(\"label\", axis=1)\n",
    "            clusters, subj_cluster = k_means(agg_train, agg_subj)\n",
    "\n",
    "            # keep only same-cluster patients\n",
    "            keep = train_ids[clusters == subj_cluster]\n",
    "            df_train = df_train[df_train[\"patient\"].isin(keep)]\n",
    "\n",
    "            folder = audeer.mkdir(os.path.join(results_path, subj))\n",
    "            preds = SVM(df_train, X_test)\n",
    "\n",
    "            df_out = df_test.assign(prediction=preds)[[\"label\", \"prediction\"]]\n",
    "            df_out.reset_index().to_csv(os.path.join(folder, \"results.csv\"), index=False)\n",
    "            all_results.append(df_out)\n",
    "\n",
    "        # unit-level metrics\n",
    "        results_df = pd.concat(all_results)\n",
    "        unit_scores = {\n",
    "            k: fn(results_df[\"label\"], results_df[\"prediction\"]) for k, fn in metrics.items()\n",
    "        }\n",
    "        with open(os.path.join(results_path, \"results.yaml\"), \"w\") as f:\n",
    "            yaml.dump(unit_scores, f)\n",
    "\n",
    "        # session-level aggregation\n",
    "        session = (\n",
    "            results_df\n",
    "            .reset_index()\n",
    "            .groupby(\"patient\")[\"prediction\"]\n",
    "            .agg(lambda x: x.value_counts().idxmax())\n",
    "            .reset_index()\n",
    "            .rename(columns={\"patient\": \"subject\"})\n",
    "        )\n",
    "        session[\"label\"] = session[\"subject\"].map(\n",
    "            lambda s: df[df[\"patient\"] == s][\"label\"].iat[0]\n",
    "        )\n",
    "        session.to_csv(os.path.join(results_path, \"results_session.csv\"), index=False)\n",
    "\n",
    "        session_scores = {\n",
    "            k: fn(session[\"label\"], session[\"prediction\"]) for k, fn in metrics.items()\n",
    "        }\n",
    "        with open(os.path.join(results_path, \"results_session.yaml\"), \"w\") as f:\n",
    "            yaml.dump(session_scores, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
